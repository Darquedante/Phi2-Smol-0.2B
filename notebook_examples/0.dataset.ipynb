{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import ujson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 处理Wiki数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_wiki_file = './data/wiki.simple.txt'\n",
    "\n",
    "liness = []\n",
    "with open(origin_wiki_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除空行\n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    if line.strip() != '':\n",
    "        new_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lines), len(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/wiki.simple_new.txt', 'w', encoding='utf-8') as f:\n",
    "#     f.writelines(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = pa.Table.from_arrays([new_lines], names=['text'])\n",
    "# compression='GZIP'\n",
    "pq.write_table(table=tb, where='./data/wiki.simple.parquet', row_group_size=50000, data_page_size=50000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 处理训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = []\n",
    "max_len = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bell_open_source/train_3.5M_CN.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        item = ujson.loads(line)\n",
    "\n",
    "        if len(item['conversations']) != 2: continue\n",
    "\n",
    "        conversation = item['conversations']\n",
    "        txt = ''\n",
    "        if conversation[0]['from'] =='human':\n",
    "            txt = f\"{conversation[0]['value']}\\n{conversation[1]['value']}\"\n",
    "        else:\n",
    "            txt = f\"{conversation[1]['value']}\\n{conversation[0]['value']}\"\n",
    "\n",
    "        if len(txt) >= max_len: continue\n",
    "        my_data.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in ['./data/bell_open_source/train_2M_CN.json', './data/bell_open_source/Belle_open_source_1M.json']:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            item = ujson.loads(line)\n",
    "\n",
    "            if item['input'].strip() != '':\n",
    "                txt = f\"{item['instruction']}\\n{item['input']}\\n{item['output']}\"\n",
    "            else:\n",
    "                txt = f\"{item['instruction']}\\n{item['output']}\"\n",
    "            \n",
    "            if len(txt) == 0 or len(txt) >= max_len: continue\n",
    "            my_data.append(\n",
    "                    txt\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(my_data), my_data[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = pa.Table.from_arrays([my_data], names=['text'])\n",
    "# compression='GZIP'\n",
    "pq.write_table(table=tb, where='./data/bell_pretrain_3M.parquet', row_group_size=20480, data_page_size=20480, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 处理sft数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/sft_0.8M_CN.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        item = ujson.loads(line)\n",
    "\n",
    "        txt = f\"{item['instruction']}{item['output']}\"\n",
    "        \n",
    "        if len(txt) == 0 or len(txt) >= 320: continue\n",
    "        lines.append(\n",
    "                item\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = pa.Table.from_pylist(lines)\n",
    "# compression='GZIP'\n",
    "pq.write_table(table=tb, where='./data/sft_train_data.parquet', row_group_size=20480, data_page_size=20480, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

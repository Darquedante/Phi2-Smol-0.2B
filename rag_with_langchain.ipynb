{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, GenerationConfig, PhiForCausalLM\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and split local knowledge documents\n",
    "Here we take the encyclopedia entry of 'Kuaizhou-1A' launched on January 11, 2024, as an example (https://baike.baidu.com/item/Kuaizhou-1A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local word vector model, using https://huggingface.co/BAAI/bge-base-zh\n",
    "# model_name = \"./data/BAAI_bge-base-zh\"\n",
    "model_name = \"BAAI/bge-base-zh\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs=model_kwargs,\n",
    "                encode_kwargs=encode_kwargs,\n",
    "                query_instruction=\"Generate vector representations of text for text retrieval\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 261, which is longer than the specified 96\n",
      "Created a chunk of size 963, which is longer than the specified 96\n",
      "Created a chunk of size 551, which is longer than the specified 96\n",
      "Created a chunk of size 499, which is longer than the specified 96\n",
      "Created a chunk of size 104, which is longer than the specified 96\n"
     ]
    }
   ],
   "source": [
    "doc_db_save_dir = './model_save/vector'\n",
    "\n",
    "if not os.path.exists(doc_db_save_dir):\n",
    "\n",
    "    # 1. Load local dataset from file\n",
    "    loader = TextLoader(\"./data/Kuaizhou-1A.txt\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    # 2. Split documents\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=96, chunk_overlap=8)\n",
    "    splited_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    # 3. Vectorize and save to local directory\n",
    "\n",
    "    db = Chroma.from_documents(splited_documents, embedding, persist_directory=doc_db_save_dir)\n",
    "    db.persist()\n",
    "else:\n",
    "    db = Chroma(persist_directory=doc_db_save_dir,  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dialogue model and construct the dialogue prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = './model_save/dpo/'\n",
    "\n",
    "model = PhiForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "phi_pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, torch_dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the near-Earth orbit payload capacity of Kuaizhou-1A?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please answer the following question based on the given background knowledge. If you do not know the information, directly answer 'No relevant answer found'.\n",
      "Below is the background knowledge:\n",
      "0. Kuaizhou-1A:\n",
      "Kuaizhou-1A (English: Kuaizhou-1A, abbreviated: KZ-1A) is a three-stage solid-fuel rocket developed by the China Aerospace Science and Industry Corporation Rocket Technology Company.\n",
      "The Kuaizhou-1A rocket is about 20 meters long, weighs about 30 tons at lift-off, has a maximum fairing diameter of 1.4 meters, a payload capacity of 200 kilograms to sun-synchronous circular orbit at 700 kilometers, and a near-Earth orbit payload capacity of 300 kilograms. The rocket uses a vehicle-mounted mobile launch method, mainly targeting micro-satellite launches and networking, and is capable of launching multiple satellites with one rocket.\n",
      "On January 11, 2024, at 11:52, China successfully launched the Tianxing-1 No. 02 satellite into space using the Kuaizhou-1A rocket from the Jiuquan Satellite Launch Center. The satellite smoothly entered its planned orbit, and the launch mission was a complete success.\n",
      "Below is the question:\n",
      "What is the near-Earth orbit payload capacity of Kuaizhou-1A?\n"
     ]
    }
   ],
   "source": [
    "# Construct the prompt\n",
    "template = \"Please answer the following question based on the given background knowledge. If you do not know the information, directly answer 'No relevant answer found'.\\nBelow is the background knowledge:\\n\"\n",
    "\n",
    "similar_docs = db.similarity_search(question, k = 1)\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    template += f\"{i}. {doc.page_content}\"\n",
    "\n",
    "template += f'\\nBelow is the question:\\n{question}'\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The near-Earth orbit payload capacity of Kuaizhou-1A is 300 kilograms.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"##Question:\\n{template}\\n##Answer:\\n\"\n",
    "outputs = phi_pipe(prompt, num_return_sequences=1, max_new_tokens=256, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "print(outputs[0]['generated_text'][len(prompt): ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
